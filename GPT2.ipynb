{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA9IDuwsBv+sWIhPnHG6dN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karankarn/GPT2/blob/main/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Z4XkkOxe3T",
        "outputId": "2534c107-8d88-4984-f006-9d61fb17f399"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN8ZVmXp6d_6",
        "outputId": "59b61178-010b-4c1b-9061-3a66c01d96e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/GPT2/input.txt\"\n",
        "\n",
        "# open input.txt and save in text\n",
        "with open (path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "# check type\n",
        "type(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len of the dataset\n",
        "print(\"length of dataset in characters :\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yErB-gtdxj8z",
        "outputId": "f8d9f404-dd49-41b6-cc8d-40989004d048"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters : 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"here are all the unique characters that occur in this text\"\"\"\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# print chars and vocab size\n",
        "print(\" \".join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5vbQNHb603x",
        "outputId": "8692f154-2e11-43ae-e399-7a3b0dfcc7bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "tokeniser\n",
        "One token is One character in this model.\n",
        "we need a strategy to tokenize i.e encode\n",
        "and decode individual characters into integers\n",
        "and back\n",
        "\"\"\"\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s:[stoi[c] for c in s] # encoder : take string, output list of integers\n",
        "decode = lambda l: \"\".join(itos[i] for i in l) # decoder : take a list of intergers, output a string\n"
      ],
      "metadata": {
        "id": "uzQVCBKQ7fz5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"Karan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUtjvXlb8bXx",
        "outputId": "12436899-a096-4764-fe55-5c5cb70db70e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23, 39, 56, 39, 52]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([23, 39, 56, 39, 52])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vmZfvrNu8euQ",
        "outputId": "29802f86-cfa7-4574-ca3d-4f97233e3fc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Karan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# encode text and wrap it in a tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "# check the shape and data type\n",
        "print(data.shape, data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di7gywbX7meo",
        "outputId": "d2f7fea6-e1bf-4f65-9e19-0cab51bd9907"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 50 elements in data,\n",
        "# which is an encoded representation of the first 50 characters of text\n",
        "print(data[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absdkxu576tn",
        "outputId": "10b4829a-89cc-40c5-f0cc-0f027bb2e9ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the characters in the novel are now represented by integers. The integers are stretched out and wrapped in a tensor. It is the entire encoding of the book."
      ],
      "metadata": {
        "id": "ITrBerwbuKMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting training and test set\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "nu10XHa_uqV2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block Size or Context Length\n",
        "All the text does not get fed into the transformer at once. Instead random chunks from the text gets fed into the transformer sequentially.\n",
        "The size of this chunk that gets fed into the transformer is referred to as context length or block size."
      ],
      "metadata": {
        "id": "foR0jaulyxYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMTa3eeizAMq",
        "outputId": "340a32ca-21f5-4ac3-cd9d-90b25041c6b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size +1]"
      ],
      "metadata": {
        "id": "mT3Gvn4DzxE0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How attention is working\n",
        "for i in range(block_size):\n",
        "  context = x[:i+1] # tensor upto this position\n",
        "  target = y[i] # should predict this tensor\n",
        "  print(f\"when input is {context} the target : {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ApzWvAV0qW5",
        "outputId": "ddc62237-a709-42e2-90ea-40f27924a41e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target : 47\n",
            "when input is tensor([18, 47]) the target : 56\n",
            "when input is tensor([18, 47, 56]) the target : 57\n",
            "when input is tensor([18, 47, 56, 57]) the target : 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target : 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target : 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target : 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target : 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its done this way to ensure the transformer is used to seeing context from just one word, all the way upto block_size and everything in between.\n",
        "\n",
        "This has advantages during inference because the transformer will be able to handle any length of input context\n",
        "\n",
        "After block size, we will need to start truncating. Because the transformer will never have context beyond this limit"
      ],
      "metadata": {
        "id": "uMuqgeiX0wSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many blocks will process in parallel\n",
        "block_size = 8 # tokens in a block"
      ],
      "metadata": {
        "id": "GTSVlDZ4L0s8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size\n",
        "For compute efficiency, multiple of the block size tensors are stacked together  to form a higher dimensional tensor, which is used as the input to the transformer.  \n",
        "\n",
        "But they dont communicate with each other or share information. They are all just processed in parallel.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-tL0V6Zy1hrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function get_batch\n",
        "  **Arguement** : dataset  \n",
        "  **Return** :   \n",
        "      1. x :  input tensor ,stack of 4 tensors,each tensor has 8 ints  \n",
        "      2. y :  target tensor ,stack of 4 tensors,each tensor has 8 ints\n",
        "\n",
        "\n",
        "    get_batch(split)  \n",
        "      data = train or val, if split = train or val\n",
        "\n",
        "      ix = a tensor of shape (batch_size,) = (4,0) filled with random integers\n",
        "\n",
        "      x = a stack of 4 tensors\n",
        "      Each tensor is 8 characters starting from ix which are random points in the text\n",
        "\n",
        "      y = a stack of 4 tensors\n",
        "      Each tensor is 8 characters starting from ix+1 which are the targets for x in the text\n",
        "\n",
        "      return x and y"
      ],
      "metadata": {
        "id": "MBYn7AzzZHc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a mini batch. which is a batchsize stack of blocks into a singe tensor\n",
        "torch.manual_seed(1337)\n",
        "def get_batch(split):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  ix = torch.randint(len(data) - block_size,(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "8b59dmmh1H9R"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = get_batch(\"train\")\n",
        "print(f\"inputs : {xb.shape} ,\\n {xb}\")\n",
        "print(f\"targets : {yb.shape} ,\\n {yb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjJWJvFxNCYE",
        "outputId": "0c897a33-01a0-4bff-dddf-fbcd2956ccef"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs : torch.Size([4, 8]) ,\n",
            " tensor([[57, 43, 60, 43, 52,  1, 63, 43],\n",
            "        [60, 43, 42,  8,  0, 25, 63,  1],\n",
            "        [56, 42,  5, 57,  1, 57, 39, 49],\n",
            "        [43, 57, 58, 63,  6,  1, 58, 46]])\n",
            "targets : torch.Size([4, 8]) ,\n",
            " tensor([[43, 60, 43, 52,  1, 63, 43, 39],\n",
            "        [43, 42,  8,  0, 25, 63,  1, 45],\n",
            "        [42,  5, 57,  1, 57, 39, 49, 43],\n",
            "        [57, 58, 63,  6,  1, 58, 46, 47]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for our mini-batch\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when input is {context.tolist()}, target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oNi3eqAcZ2b",
        "outputId": "90eae92c-452e-41ca-8500-c06a4e92b8ae"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [57], target is 43\n",
            "when input is [57, 43], target is 60\n",
            "when input is [57, 43, 60], target is 43\n",
            "when input is [57, 43, 60, 43], target is 52\n",
            "when input is [57, 43, 60, 43, 52], target is 1\n",
            "when input is [57, 43, 60, 43, 52, 1], target is 63\n",
            "when input is [57, 43, 60, 43, 52, 1, 63], target is 43\n",
            "when input is [57, 43, 60, 43, 52, 1, 63, 43], target is 39\n",
            "when input is [60], target is 43\n",
            "when input is [60, 43], target is 42\n",
            "when input is [60, 43, 42], target is 8\n",
            "when input is [60, 43, 42, 8], target is 0\n",
            "when input is [60, 43, 42, 8, 0], target is 25\n",
            "when input is [60, 43, 42, 8, 0, 25], target is 63\n",
            "when input is [60, 43, 42, 8, 0, 25, 63], target is 1\n",
            "when input is [60, 43, 42, 8, 0, 25, 63, 1], target is 45\n",
            "when input is [56], target is 42\n",
            "when input is [56, 42], target is 5\n",
            "when input is [56, 42, 5], target is 57\n",
            "when input is [56, 42, 5, 57], target is 1\n",
            "when input is [56, 42, 5, 57, 1], target is 57\n",
            "when input is [56, 42, 5, 57, 1, 57], target is 39\n",
            "when input is [56, 42, 5, 57, 1, 57, 39], target is 49\n",
            "when input is [56, 42, 5, 57, 1, 57, 39, 49], target is 43\n",
            "when input is [43], target is 57\n",
            "when input is [43, 57], target is 58\n",
            "when input is [43, 57, 58], target is 63\n",
            "when input is [43, 57, 58, 63], target is 6\n",
            "when input is [43, 57, 58, 63, 6], target is 1\n",
            "when input is [43, 57, 58, 63, 6, 1], target is 58\n",
            "when input is [43, 57, 58, 63, 6, 1, 58], target is 46\n",
            "when input is [43, 57, 58, 63, 6, 1, 58, 46], target is 47\n"
          ]
        }
      ]
    }
  ]
}